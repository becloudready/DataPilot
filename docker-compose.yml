services:
  postgres:
    image: postgres:latest
    container_name: pg-database
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: postgres
    ports:
      - "5432:5432"  # Publicly accessible on port 5432
    networks:
      - my_network  # This keeps communication internal to the Docker network (can be omitted if no internal communication needed)
    volumes:
      - pg_data:/var/lib/postgresql/data
      - ./tests/init.sql:/docker-entrypoint-initdb.d/init.sql

  datapilot:
    build: .
    container_name: datapilot-app
    ports:
      - "8501:8501"  # Publicly accessible on port 8501
    networks:
      - my_network  # Optional, remove if no communication needed with other services
    depends_on:
      - postgres

  python-script:
    image: python:3.9
    container_name: python-runner
    depends_on:
      - postgres
    networks:
      - my_network
    volumes:
      - ./tests/:/scripts  # Mount your Python script directory
    working_dir: /scripts
    entrypoint: ["sh", "-c", "pip3 install psycopg2-binary kagglehub; python3 data_import.py"]

  huggingface-tgi:
    image: ghcr.io/huggingface/text-generation-inference:latest
    container_name: text-generation-inference
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      HF_TOKEN: "${HF_TOKEN}"  # Pass the HF_TOKEN environment variable
    volumes:
      - "~/.cache/huggingface:/root/.cache/huggingface"  # Cache directory for Hugging Face
    ports:
      - "8000:80"  # Expose port 8000 on the host to port 80 in the container
    command: --model-id defog/llama-3-sqlcoder-8b
    networks:
      - my_network


volumes:
  pg_data:


networks:
  my_network:
    external: false